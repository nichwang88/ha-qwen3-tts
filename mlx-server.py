#!/usr/bin/env python3
"""
MLX-Audio FastAPI æœåŠ¡å™¨
ä½¿ç”¨ Apple Silicon GPU åŠ é€Ÿ Qwen3-TTS
æ€§èƒ½: 3-7 ç§’ç”Ÿæˆï¼ˆvs Docker CPU çš„ 39-66 ç§’ï¼‰
"""

from fastapi import FastAPI, Query, HTTPException
from fastapi.responses import FileResponse
import logging
from pathlib import Path
import mlx.core as mx
from mlx_audio.tts import load
import soundfile as sf
import numpy as np
import time
from typing import Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Qwen3-TTS MLX Server",
    description="Apple Silicon GPU åŠ é€Ÿçš„ TTS æœåŠ¡å™¨",
    version="1.0.0"
)

# å…¨å±€å˜é‡
model = None
OUTPUT_DIR = Path("/tmp/qwen3-tts-outputs")
OUTPUT_DIR.mkdir(exist_ok=True)

# æ”¯æŒçš„éŸ³è‰²
SUPPORTED_SPEAKERS = ["Vivian", "Chelsie", "Ethan"]


@app.on_event("startup")
async def load_model():
    """å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    global model
    logger.info("=" * 60)
    logger.info("ğŸš€ å¯åŠ¨ MLX-Audio TTS æœåŠ¡å™¨...")
    logger.info(f"ğŸ“ Metal GPU å¯ç”¨: {mx.metal.is_available()}")
    logger.info(f"ğŸ“ MLX è®¾å¤‡: {mx.default_device()}")

    start = time.time()
    try:
        model = load("Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice")
        load_time = time.time() - start
        logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")
        logger.info(f"ğŸ“Š æ”¯æŒçš„éŸ³è‰²: {', '.join(SUPPORTED_SPEAKERS)}")
        logger.info("=" * 60)
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}", exc_info=True)
        raise


@app.get("/")
async def root():
    """API æ ¹è·¯å¾„"""
    return {
        "service": "Qwen3-TTS MLX Server",
        "version": "1.0.0",
        "metal_gpu": mx.metal.is_available(),
        "model_loaded": model is not None,
        "endpoints": {
            "health": "/health",
            "tts": "/api/tts",
            "tts_to_speaker": "/api/tts_to_speaker"
        }
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy" if model is not None else "unhealthy",
        "model_loaded": model is not None,
        "metal_gpu": mx.metal.is_available(),
        "device": str(mx.default_device()),
        "supported_speakers": SUPPORTED_SPEAKERS
    }


@app.post("/api/tts")
async def text_to_speech(
    text: str = Query(..., description="è¦åˆæˆçš„æ–‡æœ¬"),
    speed: float = Query(1.0, ge=0.5, le=2.0, description="è¯­é€Ÿå€ç‡ (0.5-2.0)"),
    language: Optional[str] = Query("Chinese", description="è¯­è¨€"),
    speaker: Optional[str] = Query("Vivian", description="éŸ³è‰²")
):
    """
    æ–‡æœ¬è½¬è¯­éŸ³ APIï¼ˆä¸ Docker ç‰ˆæœ¬å…¼å®¹ï¼‰

    æ€§èƒ½: 3-7 ç§’ï¼ˆGPU åŠ é€Ÿï¼‰vs 39-66 ç§’ï¼ˆDocker CPUï¼‰
    """
    if model is None:
        raise HTTPException(status_code=500, detail="Model not loaded")

    logger.info(f"ğŸ“ TTS è¯·æ±‚: {text} (speaker={speaker}, speed={speed}, language={language})")

    try:
        start_time = time.time()

        # ç”Ÿæˆè¯­éŸ³
        result_gen = model.generate(
            text=text,
            voice=speaker,
            speed=speed,
            stream=False
        )

        # æå–éŸ³é¢‘
        audio_chunks = []
        sample_rate = 24000
        for chunk in result_gen:
            if hasattr(chunk, 'audio'):
                audio_chunks.append(chunk.audio)
            if hasattr(chunk, 'sample_rate'):
                sample_rate = chunk.sample_rate

        if not audio_chunks:
            raise Exception("æœªç”ŸæˆéŸ³é¢‘æ•°æ®")

        # åˆå¹¶éŸ³é¢‘
        if len(audio_chunks) == 1:
            full_audio = audio_chunks[0]
        else:
            full_audio = mx.concatenate(audio_chunks, axis=0)

        # ä¿å­˜ä¸º WAV
        output_file = OUTPUT_DIR / f"tts_{int(time.time() * 1000)}.wav"
        audio_np = np.array(full_audio)
        sf.write(str(output_file), audio_np, sample_rate)

        gen_time = time.time() - start_time
        duration = full_audio.shape[0] / sample_rate
        realtime_factor = duration / gen_time if gen_time > 0 else 0

        logger.info(
            f"âœ… è¯­éŸ³ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {gen_time:.2f}s "
            f"(éŸ³é¢‘æ—¶é•¿: {duration:.2f}s, å®æ—¶ç‡: {realtime_factor:.2f}x)"
        )

        return FileResponse(
            output_file,
            media_type="audio/wav",
            filename="output.wav",
            headers={
                "X-Generation-Time": str(gen_time),
                "X-Audio-Duration": str(duration),
                "X-Realtime-Factor": str(realtime_factor)
            }
        )

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/tts_to_speaker")
async def tts_to_speaker(
    text: str = Query(..., description="è¦åˆæˆçš„æ–‡æœ¬"),
    speaker: str = Query(..., description="éŸ³è‰²åç§°"),
    speed: float = Query(1.0, ge=0.5, le=2.0, description="è¯­é€Ÿå€ç‡")
):
    """
    æŒ‡å®šéŸ³è‰²çš„ TTS APIï¼ˆä¸ Docker ç‰ˆæœ¬å…¼å®¹ï¼‰
    """
    return await text_to_speech(
        text=text,
        speed=speed,
        language="Chinese",
        speaker=speaker
    )


if __name__ == "__main__":
    import uvicorn

    logger.info("å¯åŠ¨ Uvicorn æœåŠ¡å™¨...")
    logger.info("ç›‘å¬åœ°å€: 0.0.0.0:7861")
    logger.info("è®¿é—® http://localhost:7861/docs æŸ¥çœ‹ API æ–‡æ¡£")

    uvicorn.run(
        app,
        host="0.0.0.0",
        port=7861,
        log_level="info"
    )
